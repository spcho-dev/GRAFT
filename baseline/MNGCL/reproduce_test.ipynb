{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b0772b",
   "metadata": {},
   "source": [
    "## MNGCL Reproduction Test\n",
    "### This notebook demonstrates the reproduction of MNGCL model performance on using pre-trained weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906059e8",
   "metadata": {},
   "source": [
    "\n",
    "#### Setup and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec77e022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADS_Lab\\anaconda3\\envs\\mngcl2copy\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics, linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import average_precision_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from reproduction_utils import MNGCL, GCN\n",
    "\n",
    "# Device Configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = \"../../Data/STRING/\"\n",
    "DATA_PATH_2 = \"./Data/\" \n",
    "FOLD_PATH = \"../../Data/STRING/10fold/fold_3\"\n",
    "MODEL_PATH = \"./Data/MNGCL.pt\"\n",
    "\n",
    "# Check if model exists\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"Warning: Model file '{MODEL_PATH}' not found. Please train the model and save the weights first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ddd626",
   "metadata": {},
   "source": [
    "#### Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a464f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kfold_data(fold_path, device):\n",
    "    \"\"\"Load train/valid/test split indices and masks for a specific fold.\"\"\"\n",
    "    \n",
    "    # Load Indices\n",
    "    train_idx = np.loadtxt(f\"{fold_path}/train.txt\", dtype=int)\n",
    "    valid_idx = np.loadtxt(f\"{fold_path}/valid.txt\", dtype=int)\n",
    "    test_idx = np.loadtxt(f\"{fold_path}/test.txt\", dtype=int)\n",
    "    \n",
    "    # Load Masks\n",
    "    train_mask = torch.tensor(np.loadtxt(f\"{fold_path}/train_mask.txt\", dtype=bool), device=device)\n",
    "    valid_mask = torch.tensor(np.loadtxt(f\"{fold_path}/valid_mask.txt\", dtype=bool), device=device)\n",
    "    test_mask = torch.tensor(np.loadtxt(f\"{fold_path}/test_mask.txt\", dtype=bool), device=device)\n",
    "    \n",
    "    # Load Labels\n",
    "    labels = torch.tensor(np.loadtxt(f\"{fold_path}/labels.txt\"), dtype=torch.float32, device=device)\n",
    "    \n",
    "    print(f\"train/valid/test data load completed\")\n",
    "    \n",
    "    return train_idx, valid_idx, test_idx, train_mask, valid_mask, test_mask, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac0137b",
   "metadata": {},
   "source": [
    "#### Load Data (Features & Graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32dfa8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Multi-omics Features...\n",
      "Feature shape: torch.Size([10251, 48])\n",
      "Features with node2vec: torch.Size([10251, 64])\n",
      "\n",
      "Loading Graph Adjacency Matrices...\n",
      "Graphs loaded successfully.\n",
      "\n",
      "Loading ...\n",
      "train/valid/test data load completed\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Multi-omics Features...\")\n",
    "\n",
    "try:\n",
    "    data_x_df = pd.read_csv(DATA_PATH + 'multiomics_features_STRING.tsv', sep='\\t', index_col=0)\n",
    "    data_x_df = data_x_df.dropna()\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(data_x_df.values)\n",
    "    data_x = torch.tensor(features_scaled, dtype=torch.float32, device=DEVICE)\n",
    "    \n",
    "    # Use Pan-Cancer features (first 48 dimensions)\n",
    "    data_x = data_x[:, :48]\n",
    "    print(f\"Feature shape: {data_x.shape}\")\n",
    "    \n",
    "    try:\n",
    "        dataz = torch.load(DATA_PATH_2 + \"Str_feature_STRING.pkl\", map_location=DEVICE)\n",
    "        data_x = torch.cat((data_x, dataz), 1)\n",
    "        print(f\"Features with node2vec: {data_x.shape}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Node2vec features not found, proceeding without them.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading features: {e}\")\n",
    "\n",
    "print(\"\\nLoading Graph Adjacency Matrices...\")\n",
    "try:\n",
    "    ppiAdj = torch.load(DATA_PATH + 'STRING_ppi.pkl', map_location=DEVICE)\n",
    "    ppiAdj_self = torch.load(DATA_PATH_2 + 'STRING_ppi_selfloop.pkl', map_location=DEVICE)\n",
    "    pathAdj = torch.load(DATA_PATH + 'pathway_SimMatrix_filtered.pkl', map_location=DEVICE)\n",
    "    goAdj = torch.load(DATA_PATH + 'GO_SimMatrix_filtered.pkl', map_location=DEVICE)\n",
    "    \n",
    "    pos = ppiAdj_self.to_dense().to(DEVICE)\n",
    "    \n",
    "    print(\"Graphs loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading graphs: {e}\")\n",
    "\n",
    "print(\"\\nLoading ...\")\n",
    "train_idx, valid_idx, test_idx, train_mask, valid_mask, test_mask, Y = load_kfold_data(FOLD_PATH, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472f44fa",
   "metadata": {},
   "source": [
    "#### Initialize Model & Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27559573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained model weights loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Configuration (training config)\n",
    "INPUT_DIM = data_x.shape[1]\n",
    "HIDDEN_DIM = 300\n",
    "OUTPUT_DIM = 100\n",
    "TAU = 0.5\n",
    "\n",
    "# Initialize GCN\n",
    "gcn = GCN(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM).to(DEVICE)\n",
    "\n",
    "# Initialize MNGCL\n",
    "model = MNGCL(\n",
    "    gnn=gcn,\n",
    "    pos=pos,\n",
    "    tau=TAU,\n",
    "    gnn_outsize=OUTPUT_DIM,\n",
    "    projection_hidden_size=300,\n",
    "    projection_size=100\n",
    ").to(DEVICE)\n",
    "\n",
    "# Load Pre-trained Weights\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "    print(\"Pre-trained model weights loaded successfully.\")\n",
    "else:\n",
    "    print(\"Model weights not found. Cannot proceed with inference.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd8d438",
   "metadata": {},
   "source": [
    "#### Inference & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a9a6b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Inference...\n",
      "Training Logistic Regression on learned embeddings...\n",
      "\n",
      "========================================\n",
      "MNGCL Reproduction Results\n",
      "========================================\n",
      "AUROC    : 0.8757\n",
      "AUPRC    : 0.7809\n",
      "F1-Score : 0.7568\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "def LogReg(train_x, train_y, test_x):\n",
    "    \"\"\"Logistic Regression classifier for final prediction\"\"\"\n",
    "    regr = linear_model.LogisticRegression(max_iter=10000)\n",
    "    regr.fit(train_x, train_y.ravel())\n",
    "    pre = regr.predict_proba(test_x)\n",
    "    pre = pre[:, 1]\n",
    "    return pre\n",
    "\n",
    "print(\"Running Inference...\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Prepare sparse indices for ChebConv\n",
    "    ppiAdj_index = ppiAdj.coalesce().indices().to(DEVICE)\n",
    "    pathAdj_index = pathAdj.coalesce().indices().to(DEVICE)\n",
    "    goAdj_index = goAdj.coalesce().indices().to(DEVICE)\n",
    "    \n",
    "    # Forward Pass\n",
    "    # MNGCL forward returns: emb1, emb2, emb3, concatenated_emb, loss\n",
    "    _, _, _, emb, _ = model(ppiAdj_index, pathAdj_index, goAdj_index, \n",
    "                            data_x, data_x, data_x)\n",
    "    \n",
    "    # Extract embeddings for train/test sets\n",
    "    train_x_emb = torch.sigmoid(emb[train_mask]).cpu().detach().numpy()\n",
    "    train_y_label = Y[train_mask].cpu().numpy()\n",
    "    \n",
    "    test_x_emb = torch.sigmoid(emb[test_mask]).cpu().detach().numpy()\n",
    "    test_y_label = Y[test_mask].cpu().numpy()\n",
    "    \n",
    "    # Final Prediction using Logistic Regression\n",
    "    print(\"Training Logistic Regression on learned embeddings...\")\n",
    "    preds = LogReg(train_x_emb, train_y_label, test_x_emb)\n",
    "    \n",
    "    # Calculate Metrics\n",
    "    auc = metrics.roc_auc_score(test_y_label, preds)\n",
    "    auprc = average_precision_score(test_y_label, preds)\n",
    "    f1 = f1_score(test_y_label, (preds > 0.5).astype(int))\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"MNGCL Reproduction Results\")\n",
    "print(\"=\"*40)\n",
    "print(f\"AUROC    : {auc:.4f}\")\n",
    "print(f\"AUPRC    : {auprc:.4f}\")\n",
    "print(f\"F1-Score : {f1:.4f}\")\n",
    "print(\"=\"*40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mngcl2copy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
