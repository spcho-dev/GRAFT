{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7f51f51",
   "metadata": {},
   "source": [
    "## EMGNN Reproduction Test\n",
    "### This notebook demonstrates the reproduction of EMGNN model performance on using pre-trained weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f729fd",
   "metadata": {},
   "source": [
    "#### Library import and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b88a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADS_Lab\\anaconda3\\envs\\mngcl2copy\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from reproduction_utils import EMGNN, cal_metrics\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b158fd80",
   "metadata": {},
   "source": [
    "#### Setting up and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dac730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading Global Data & Preprocessing...\n",
      "Global Data Setup Complete.\n"
     ]
    }
   ],
   "source": [
    "FOLD_TO_LOAD = 3\n",
    "MODEL_PATH = f\"./Data/EMGNN.pt\"\n",
    "\n",
    "class Args:\n",
    "    hidden = 64\n",
    "    n_layers = 3\n",
    "    dropout = 0.5\n",
    "    alpha = 0.2\n",
    "    nb_heads = 1\n",
    "    # Model Type\n",
    "    gat = False\n",
    "    gcn = True\n",
    "    gin = False\n",
    "    mlp = False\n",
    "\n",
    "args = Args()\n",
    "\n",
    "print(\">>> Loading Global Data & Preprocessing...\")\n",
    "\n",
    "features_order = ['MF: KIRC', 'MF: BRCA', 'MF: READ', 'MF: PRAD', 'MF: STAD', 'MF: HNSC',\n",
    " 'MF: LUAD', 'MF: THCA', 'MF: BLCA', 'MF: ESCA', 'MF: LIHC', 'MF: UCEC',\n",
    " 'MF: COAD', 'MF: LUSC', 'MF: CESC', 'MF: KIRP', 'METH: KIRC', 'METH: BRCA',\n",
    " 'METH: READ', 'METH: PRAD', 'METH: STAD', 'METH: HNSC', 'METH: LUAD',\n",
    " 'METH: THCA', 'METH: BLCA', 'METH: ESCA', 'METH: LIHC', 'METH: UCEC',\n",
    " 'METH: COAD', 'METH: LUSC', 'METH: CESC', 'METH: KIRP', 'GE: KIRC', 'GE: BRCA',\n",
    " 'GE: READ', 'GE: PRAD', 'GE: STAD', 'GE: HNSC', 'GE: LUAD', 'GE: THCA',\n",
    " 'GE: BLCA', 'GE: ESCA', 'GE: LIHC', 'GE: UCEC', 'GE: COAD', 'GE: LUSC',\n",
    " 'GE: CESC', 'GE: KIRP', 'CNA: KIRC', 'CNA: BRCA', 'CNA: READ', 'CNA: PRAD',\n",
    " 'CNA: STAD', 'CNA: HNSC', 'CNA: LUAD', 'CNA: THCA', 'CNA: BLCA', 'CNA: ESCA',\n",
    " 'CNA: LIHC', 'CNA: UCEC', 'CNA: COAD', 'CNA: LUSC', 'CNA: CESC', 'CNA: KIRP']\n",
    "\n",
    "gene_index_file = \"./Data/STRING_gene_index_mapping.tsv\"\n",
    "node_df = pd.read_csv(gene_index_file, sep=\"\\t\")\n",
    "node_names = node_df[\"gene\"].values\n",
    "num_nodes = len(node_names)\n",
    "node_to_index = {gene: idx for idx, gene in enumerate(node_names)}\n",
    "\n",
    "ppi_file = \"../../Data/STRING/STRING_ppi_edgelist.tsv\"\n",
    "ppi_df = pd.read_csv(ppi_file, sep=\"\\t\")\n",
    "ppi_df = ppi_df[ppi_df[\"partner1\"].isin(node_to_index) & ppi_df[\"partner2\"].isin(node_to_index)]\n",
    "\n",
    "adj = np.zeros((num_nodes, num_nodes))\n",
    "for _, row in ppi_df.iterrows():\n",
    "    i, j = node_to_index[row[\"partner1\"]], node_to_index[row[\"partner2\"]]\n",
    "    confidence = row[\"confidence\"] / 1000 \n",
    "    adj[i, j] = confidence\n",
    "    adj[j, i] = confidence \n",
    "\n",
    "features_file = \"../../Data/STRING/multiomics_features_STRING.tsv\"\n",
    "features_df = pd.read_csv(features_file, sep=\"\\t\", index_col=0)\n",
    "features = features_df.values \n",
    "feature_names = features_df.columns.values\n",
    "feature_names = [str(f) for f in feature_names] \n",
    "\n",
    "feature_ind = [feature_names.index(f_n) for f_n in features_order if f_n in feature_names]\n",
    "features = features[:, feature_ind]\n",
    "\n",
    "adj = torch.FloatTensor(adj)\n",
    "features = torch.FloatTensor(features)\n",
    "\n",
    "node2idx = {}\n",
    "counter = 0\n",
    "meta_x = torch.zeros((100000, 64))\n",
    "meta_y = torch.zeros(1000000, 1) \n",
    "\n",
    "for i in node_names:\n",
    "    if i not in node2idx:\n",
    "        node2idx[i] = counter\n",
    "        counter += 1\n",
    "\n",
    "label_file = f\"../../Data/STRING/10fold/fold_{FOLD_TO_LOAD}/labels.txt\"\n",
    "with open(label_file, \"r\") as f:\n",
    "    labels_all = [int(line.strip()) for line in f.readlines()]\n",
    "y_all = torch.tensor(labels_all, dtype=torch.long)\n",
    "\n",
    "for i, label in enumerate(y_all):\n",
    "    idx = node2idx[node_names[i]]\n",
    "    if isinstance(features, torch.Tensor):\n",
    "        meta_x[idx] = features[i]\n",
    "    else:\n",
    "        meta_x[idx] = torch.tensor(features[i])\n",
    "        \n",
    "    if(meta_y[idx] == 0):\n",
    "        meta_y[idx] = label\n",
    "\n",
    "print(\"Global Data Setup Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a8349c",
   "metadata": {},
   "source": [
    "#### Load fold data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b72f2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading Data ...\n",
      "Data Loaded. Test Nodes: 97\n"
     ]
    }
   ],
   "source": [
    "print(f\">>> Loading Data ...\")\n",
    "\n",
    "fold_path = f\"../../Data/STRING/10fold/fold_{FOLD_TO_LOAD}\"\n",
    "\n",
    "train_mask = np.loadtxt(os.path.join(fold_path, \"train_mask.txt\"), dtype=int)\n",
    "val_mask = np.loadtxt(os.path.join(fold_path, \"valid_mask.txt\"), dtype=int)\n",
    "test_mask = np.loadtxt(os.path.join(fold_path, \"test_mask.txt\"), dtype=int)\n",
    "labels = np.loadtxt(os.path.join(fold_path, \"labels.txt\"), dtype=int)\n",
    "\n",
    "idx_train = torch.LongTensor([i for i in range(num_nodes) if train_mask[i]])\n",
    "idx_test = torch.LongTensor([i for i in range(num_nodes) if test_mask[i]])\n",
    "\n",
    "edge_index = (adj > 0).nonzero().t()\n",
    "edge_index, _ = add_self_loops(edge_index)\n",
    "\n",
    "data = Data(x=features, edge_index=edge_index, y=torch.tensor(labels), node_names=node_names)\n",
    "\n",
    "data = data.to(device)\n",
    "meta_x = meta_x.to(device)\n",
    "idx_test = idx_test.to(device)\n",
    "\n",
    "print(f\"Data Loaded. Test Nodes: {len(idx_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bb9e32",
   "metadata": {},
   "source": [
    "#### Initialize model and load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "690ce587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Initializing Model...\n",
      "Successfully loaded weights from ./Data/EMGNN.pt\n"
     ]
    }
   ],
   "source": [
    "print(\">>> Initializing Model...\")\n",
    "\n",
    "nfeat = features.shape[1]\n",
    "\n",
    "model = EMGNN(nfeat,\n",
    "              args.hidden,\n",
    "              args.n_layers,\n",
    "              nclass=2,\n",
    "              args=args,\n",
    "              data=data,\n",
    "              meta_x=meta_x,\n",
    "              node2idx=node2idx)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device), strict=False)\n",
    "    print(f\"Successfully loaded weights from {MODEL_PATH}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Checkpoint not found: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af96e23a",
   "metadata": {},
   "source": [
    "#### Inference and Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00306d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">>> Running Inference...\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(data.x, data.edge_index, data)\n",
    "    \n",
    "    output_prob = torch.exp(output)\n",
    "    y_pred_prob = output_prob[idx_test][:, 1].cpu().numpy()\n",
    "    \n",
    "    y_true = data.y[idx_test].cpu().numpy()\n",
    "    \n",
    "    acc, auroc, auprc, f1 = cal_metrics(y_true, y_pred_prob)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"EMGNN Reproduction Results\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"AUROC    : {auroc:.4f}\")\n",
    "    print(f\"AUPRC    : {auprc:.4f}\")\n",
    "    print(f\"F1-Score : {f1:.4f}\")\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(\"=\"*40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mngcl2copy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
